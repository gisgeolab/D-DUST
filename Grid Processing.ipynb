{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a595331",
   "metadata": {
    "tags": []
   },
   "source": [
    "# D-DUST - Data Grid Processing\n",
    "\n",
    "<img style=\"margin-right:20px;\" src=img/DDUST__Nero.png width=\"150\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901b5dae",
   "metadata": {
    "tags": []
   },
   "source": [
    "This notebook processes the data and generates the grids used for the next modeling steps. \n",
    "The following table contains the documentation and the information about the project structure and the variable used: <br>\n",
    "\n",
    "| Product Description | Link |\n",
    "|:--------------------:|:-----------------------:|\n",
    "| Data Management Plan (DMP) | <a href=\"https://docs.google.com/document/d/1ecJ6BiCxtJ5ObQAa15eB5eGze9JGMik9/edit\" target=\"_blank\">link</a> |\n",
    "| Data Table |<a href=\"https://docs.google.com/spreadsheets/d/1-5pwMSc1QlFyC8iIaA-l1fWhWtpqVio2/edit#gid=91313358\" target=\"_blank\">link</a>|\n",
    "\n",
    "First, the listed notebooks must be used to retrieve all the data to be processed in the selected time range. For each dataset, a description is provided in the Data Table and corresponding notebooks:\n",
    "- [Satellite Variables Request Notebook](https://github.com/opengeolab/D-DUST/blob/WP2/Satellite%20Variables%20Request.ipynb): satellite data download and preparation (e.g. Sentinel-5P);\n",
    "- [Model Variables Request Notebook](https://github.com/opengeolab/D-DUST/blob/WP2/Model%20Variables%20Request.ipynb): Copernicus CAMS and ERA5 model data download and preparation;\n",
    "- [Ground Sensor Variables Request Notebook](https://github.com/opengeolab/D-DUST/blob/WP2/Ground%20Sensor%20Variables%20Request%20-%20ARPA%20Lombardia.ipynb): ARPA and ESA Air Quality sensor data download and preparation.\n",
    "\n",
    "This notebook summarizes the physical variables selected for the project and how they are processed for the successive phase of feature selection and ML modeling. <br>\n",
    "These variables are divided into <u>4 categories</u>, as shown in the Data Table:\n",
    "1. `Map Layer`: time-invariant layer used to describe Lombardy region morphology and its features (e.g. elevation, infrastructures, land use and cover, etc.)\n",
    "2. `Model`: data retrieved from a model that uses satellite and in-situ observations of meteorological and air quality data as input (e.g. ERA5, CAMS)\n",
    "3. `Satellite`: data obtained directly from satellite observations (e.g. Sentinel-5P Tropomi or Terra&Aqua MODIS)\n",
    "4. `Ground Sensor`: data retrieved from ground monitoring stations measuring air quality and meteorological variables (in this case ARPA Lombardia and ESA LPS Air Quality Stations).\n",
    "\n",
    "All the physical variables are represented using zonal statistics (depending on the variable the summary statistic can be sum, density, categorical data, etc.). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b0316e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff716c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "import scipy.interpolate\n",
    "from scipy.interpolate import griddata\n",
    "import rasterstats as rstat\n",
    "import rioxarray\n",
    "import shapely.speedups\n",
    "shapely.speedups.enable()\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "from shapely.geometry import shape\n",
    "from shapely.geometry import  MultiLineString\n",
    "from rasterio.enums import Resampling\n",
    "import ipywidgets as widgets\n",
    "import json\n",
    "import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import methods defined for the project\n",
    "from functions import DDUST_methods\n",
    "\n",
    "# Get current working directory path\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972837ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import grids and define time range\n",
    "\n",
    "Three grids with different spatial resolutions are used in this project:\n",
    "1. `grid_0_1`: 0.1° x 0.1° resolution - Grid with CAMS Model spatial resolution.\n",
    "2. `grid_0_066`: 0.066° x 0.066° resolution - Grid with the Sentinel-5P approximate spatial resolution.\n",
    "3. `grid_0_01`: 0.01° x 0.01° resolution- Grid generated with at most one ARPA monitoring station for each pixel.\n",
    "\n",
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "<span>&#9888;</span>\n",
    "<a id='warning'></a> To complete the processing using a grid with 0.01° resolution could also take some hours, depending and your computer performances.\n",
    "</div>\n",
    "\n",
    "These grids are defined as the bounding box of the Lombardy region layer applying a buffer of 20 km."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf62a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With this widget is possible to select from the dropdown list\n",
    "name = widgets.Dropdown(\n",
    "    options=['0_1', '0_066', '0_01'],\n",
    "    description='Grid resolution:',\n",
    "    disabled=False, style = {'description_width': '100px'})\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265cc34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion for lengths and areas\n",
    "m_to_km = 10**(-3)\n",
    "m2_to_km2 = 10**(-6)\n",
    "\n",
    "# To increase CAMS data resolution depending on the grid cell size (necessary zonal statistics calculation)\n",
    "if name.value == '0_1':\n",
    "    upscale_factor = 1\n",
    "if name.value == '0_066':\n",
    "    upscale_factor = 5\n",
    "if name.value == '0_01':\n",
    "    upscale_factor = 15  \n",
    "\n",
    "#Select grid based on selection\n",
    "grid_path = my_methods.select_grid(name.value)\n",
    "\n",
    "#Select empty grid\n",
    "grid = gpd.read_file(cwd + grid_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037ed688",
   "metadata": {},
   "source": [
    "Selection of time periods throughout all the notebooks defined in the `date.json` file, providing the year and the time range (using a custom week with mm-dd format):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2170c6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = open('date.json') # Select time range\n",
    "date = json.load(d)\n",
    "year = date['year']\n",
    "custom_week = date['custom_week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41eddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select start and end date\n",
    "start_date = datetime.datetime.strptime((str(year)+'-'+custom_week[0]), \"%Y-%m-%d\").date()\n",
    "end_date = datetime.datetime.strptime((str(year)+'-'+custom_week[1]), \"%Y-%m-%d\").date()\n",
    "print(\"The starting date is\", start_date,\"and the ending date is\" , end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02584c7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3479eb93",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Map Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382fae5f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "<a id='warning'></a> Map Layers don't update as frequently as satellite, model, and ground sensor data.\n",
    "They can be stored in folders and replaced when a newer version is provided. It is possible to save a preprocessed version of the grids at the end of the Map Layer section, to avoid calculations when these data remain the same. These grids are saved with `_prep` tag (e.g. grid_0_01_prep.gpkg).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12705ddb-3a0d-43b3-978e-33ffbbfc874e",
   "metadata": {},
   "source": [
    "[**PRESS TO SKIP MAP LAYERS PROCESSING**](#not-map-layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fbe55e-ab16-47fc-a8e7-63e0371c7f8a",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2bfc48",
   "metadata": {},
   "source": [
    "### [Digital Terrain Model - Geoportale Lombardia](https://www.geoportale.regione.lombardia.it/metadati?p_p_id=detailSheetMetadata_WAR_gptmetadataportlet&p_p_lifecycle=0&p_p_state=normal&p_p_mode=view&_detailSheetMetadata_WAR_gptmetadataportlet_uuid=%7BFC06681A-2403-481F-B6FE-5F952DD48BAF%7D)<br>\n",
    "Digital Terrain Model of Lombardy region with 20 m resolution. Reference system EPSG:4326.\n",
    "1. `Elevation` = Lombardy Region DTM with 20 m resolution;\n",
    "2. `Aspect` = aspect calculated from the elevation layer;\n",
    "3. `Slope` = slope calculated from the elevation layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80a33a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import paths\n",
    "dtm_path = cwd + '/terrain/dtm20.tif'\n",
    "aspect_path = cwd + '/terrain/aspect.tif'\n",
    "slope_path = cwd + '/terrain/slope.tif'\n",
    "dtm = rio.open(dtm_path)\n",
    "aspect = rio.open(aspect_path)\n",
    "slope = rio.open(slope_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b9d009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates mean value in each cell for the DTM elevation\n",
    "dtm_array = dtm.read(1)\n",
    "dtm_array[dtm_array<0]=np.nan\n",
    "dtm_affine = dtm.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, dtm_array, affine=dtm_affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"h_mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b7924f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Class majority value in each cell for aspect\n",
    "aspect_array = aspect.read(1)\n",
    "aspect_array[aspect_array<0]=np.nan\n",
    "aspect_affine = aspect.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, aspect_array, affine=aspect_affine, nodata=np.nan, stats=['majority'])), how='left')\n",
    "grid = grid.rename(columns={\"majority\": \"aspect_major\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d494fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculates mean value in each cell for slope\n",
    "slope_array = slope.read(1)\n",
    "slope_array[slope_array<0]=np.nan\n",
    "slope_affine = slope.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, slope_array, affine=slope_affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"slope_mean\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74615632",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5e7153-a9e8-4b3d-b2a4-37dac457d0e7",
   "metadata": {},
   "source": [
    "### [Air quality zones - Geoportale Lombardia](https://www.geoportale.regione.lombardia.it/metadati?p_p_id=detailSheetMetadata_WAR_gptmetadataportlet&p_p_lifecycle=0&p_p_state=normal&p_p_mode=view&_detailSheetMetadata_WAR_gptmetadataportlet_uuid=%7B20A92F5C-A3EC-402C-B908-EE32EB8644C2%7D)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d838ce3c-6cbd-4d8d-9a3a-e6ad4cd71dcc",
   "metadata": {},
   "source": [
    "Air quality zones. Reference system EPSG:4326. These are divided into 5 categories and assigned to the following values:\n",
    "- `1` = A. Highly urbanized plains\n",
    "- `2` = B. Plains\n",
    "- `3` = C. Prealpi, Appennino and mountains\n",
    "- `4` = D. Valley floor\n",
    "- `5` = Agg. Urban agglomarated area (Milano, Bergamo, Brescia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422872c9-6266-4d09-bef7-4f597210abcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import path\n",
    "aq_zones_path = cwd + '/zones/air_quality_zones.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af306f7-6a0e-43b6-97b4-1713fb61caf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_zones = rio.open(aq_zones_path)\n",
    "aq_zones_array = aq_zones.read(1).astype('float64') \n",
    "aq_zones_array[aq_zones_array<1.0]=np.nan\n",
    "aq_zones_affine = aq_zones.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21edd86b-3bd2-4e41-b2a2-65350bb870aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class majority calculation for each cell\n",
    "stats_aq_zones = rstat.zonal_stats(grid, aq_zones_array, affine=aq_zones_affine, nodata=np.nan, stats=['majority'], categorical=True)\n",
    "majority_list = [{k: v for k, v in d.items() if k == 'majority'} for d in stats_aq_zones]\n",
    "grid = grid.join(pd.DataFrame(majority_list), how='left')\n",
    "grid = grid.rename(columns={\"majority\": \"aq_zone\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1225197d-464e-4962-a203-2fff45ebf96f",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff847955-14ec-4fb1-b0ed-b444231fa512",
   "metadata": {
    "tags": []
   },
   "source": [
    "### [Zone pedoclimatiche](https://www.ersaf.lombardia.it/it/servizi-al-territorio/nitrati/bollettini-nitrati/bollettino-nitrati)<br>\n",
    "Homogeneous areas from the perspective of factors involving soil and climate conditions (from Allegato B Bollettino nitrati - ERSAF. More information in the Data Table). Reference system EPSG:4326. These are divided into 6 categories and assigned to the following values:\n",
    "\n",
    "- `1` = Alpi\n",
    "- `2` = Prealpi Occidentali\n",
    "- `3` = Prealpi Orientali\n",
    "- `4` = Pianura Occidentale\n",
    "- `5` = Pianura Centrale\n",
    "- `6` = Pianura Orientale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53819ce1-c27c-4ded-b886-1a0d647560c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import path\n",
    "clim_zones_path = cwd + '/zones/climate_zones.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772280d3-6892-4aac-b151-bc6d32f45599",
   "metadata": {},
   "outputs": [],
   "source": [
    "clim_zones = rio.open(clim_zones_path)\n",
    "clim_zones_array = clim_zones.read(1).astype('float64') \n",
    "clim_zones_array[clim_zones_array<1.0]=np.nan\n",
    "clim_zones_affine = clim_zones.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd536832-618e-492d-8ad0-1d37e36dcf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class majority calculation for each cell\n",
    "stats_clim_zones = rstat.zonal_stats(grid, clim_zones_array, affine=clim_zones_affine, nodata=np.nan, stats=['majority'], categorical=True)\n",
    "majority_list = [{k: v for k, v in d.items() if k == 'majority'} for d in stats_clim_zones]\n",
    "grid = grid.join(pd.DataFrame(majority_list), how='left')\n",
    "grid = grid.rename(columns={\"majority\": \"clim_zone\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abe2abe",
   "metadata": {},
   "source": [
    "- - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3daa1b51",
   "metadata": {
    "tags": []
   },
   "source": [
    "### [Gridded Population of the World - GPW](https://sedac.ciesin.columbia.edu/data/set/gpw-v4-population-density-rev11)<br>\n",
    "Population density for the year 2020, based on counts consistent with national censuses and population registers, as raster data to facilitate data integration.\n",
    "Reference system EPSG: 32632."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa462e06-3be7-4efa-88e6-7a5df816e356",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change reference system to EPSG:32632 (WGS84 - UTM32N)\n",
    "grid = grid.to_crs(32632)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81549559",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_path = cwd + '/population/population.tif'\n",
    "pop = rio.open(pop_path)\n",
    "\n",
    "#Calculates density of pupulation\n",
    "pop_array = pop.read(1)\n",
    "pop_array[pop_array<0]=np.nan\n",
    "pop_affine = pop.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, pop_array, affine=pop_affine, nodata=np.nan, stats=['sum'])), how='left')\n",
    "grid = grid.rename(columns={\"sum\": \"pop\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bc4356",
   "metadata": {
    "tags": []
   },
   "source": [
    "### [DUSAF - Land use - Geoportale Lombardia](https://www.geoportale.regione.lombardia.it/metadati?p_p_id=detailSheetMetadata_WAR_gptmetadataportlet&p_p_lifecycle=0&p_p_state=normal&p_p_mode=view&_detailSheetMetadata_WAR_gptmetadataportlet_uuid=%7B18EE7CDC-E51B-4DFB-99F8-3CF416FC3C70%7D) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffe9826",
   "metadata": {},
   "source": [
    "Consists in a multi-temporal geographic database that classifies land based on major land cover and land use types. It's required to provide this file in .tiff format (must be rasterized since it's a vector file). \n",
    "Reference system EPSG:32632.<br> \n",
    "\n",
    "DUSAF Land Use categories considered for Lombardy region are 8:\n",
    "- `2` = Agricultural areas\n",
    "- `3` = Wooded territories and semi-natural environments\n",
    "- `4` = Wetlands\n",
    "- `5` = Water bodies\n",
    "- `11` = Urbanised areas\n",
    "- `12` = Production facilities, large plants and communication networks\n",
    "- `13` = Mining areas, landfills, construction sites, waste and abandoned land\n",
    "- `14` = Non-agricultural green areas\n",
    "\n",
    "The class majority in each cell is stored in the `dusaf` variable, while the `dsf_X` contains the area % of each category in each pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fb8c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set DUSAF raster path\n",
    "dusaf_path = cwd + '/land_use_cover/dusaf.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a13eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dusaf = rio.open(dusaf_path) #open DUSAF with rasterio\n",
    "dusaf_array = dusaf.read(1).astype('float64') \n",
    "dusaf_array[dusaf_array<1.0]=np.nan\n",
    "dusaf_affine = dusaf.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3a5636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class majority calculation for each cell\n",
    "stats_dusaf = rstat.zonal_stats(grid, dusaf_array, affine=dusaf_affine, nodata=0.0, stats=['majority'], categorical=True)\n",
    "majority_list = [{k: v for k, v in d.items() if k == 'majority'} for d in stats_dusaf]\n",
    "grid = grid.join(pd.DataFrame(majority_list), how='left')\n",
    "grid = grid.rename(columns={\"majority\": \"dusaf\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fb2405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate area fractions for each class in each cell\n",
    "stats_dusaf = rstat.zonal_stats(grid, dusaf_array, affine=dusaf_affine, nodata=0.0, stats=['count'], categorical=True)\n",
    "p = pd.DataFrame.from_dict(stats_dusaf, orient='columns')\n",
    "\n",
    "grid.loc[grid.dusaf.notnull(), ['dsf2','dsf3','dsf4','dsf5','dsf11','dsf12','dsf13','dsf14']] = 0.0\n",
    "\n",
    "grid['p2'] = p[2.0] / p['count']\n",
    "grid['p3'] = p[3.0] / p['count']\n",
    "grid['p4'] = p[4.0] / p['count']\n",
    "grid['p5'] = p[5.0] / p['count']\n",
    "grid['p11'] = p[11.0] / p['count']\n",
    "grid['p12'] = p[12.0] / p['count']\n",
    "grid['p13'] = p[13.0] / p['count']\n",
    "grid['p14'] = p[14.0] / p['count']\n",
    "grid.dsf2 = np.nanmax(grid[['dsf2', 'p2']],1)\n",
    "grid.dsf3 = np.nanmax(grid[['dsf3', 'p3']],1)\n",
    "grid.dsf4 = np.nanmax(grid[['dsf4', 'p4']],1)\n",
    "grid.dsf5 = np.nanmax(grid[['dsf5', 'p5']],1)\n",
    "grid.dsf11 = np.nanmax(grid[['dsf11', 'p11']],1)\n",
    "grid.dsf12 = np.nanmax(grid[['dsf12', 'p12']],1)\n",
    "grid.dsf13 = np.nanmax(grid[['dsf13', 'p13']],1)\n",
    "grid.dsf14 = np.nanmax(grid[['dsf14', 'p14']],1)\n",
    "\n",
    "grid = grid.drop(columns=['p2', 'p3', 'p4', 'p5', 'p11', 'p12', 'p13', 'p14'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ba17ce",
   "metadata": {},
   "source": [
    " - - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1b2e46",
   "metadata": {},
   "source": [
    "### [SIARL - Agricultural use - Geoportale Lombardia](https://www.geoportale.regione.lombardia.it/metadati?p_p_id=detailSheetMetadata_WAR_gptmetadataportlet&p_p_lifecycle=0&p_p_state=normal&p_p_mode=view&_detailSheetMetadata_WAR_gptmetadataportlet_uuid=%7B83483117-8742-4A1F-A16E-3A48AEE2EBE2%7D) <br>\n",
    "This layer contains the agricoltural use for each cadastral parcel provided by SIARL Catalog for the Lombardy region converted to .tif format. Reference system EPSG:32632. <br>\n",
    "\n",
    "Interesting SIARL Agricoltural considered for Lombardy region are 3:\n",
    "- `2` = Cereal\n",
    "- `9` = Mais\n",
    "- `12` = Rice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b49d827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set SIARL raster path\n",
    "siarl_path = cwd + '/land_use_cover/siarl.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a2089d",
   "metadata": {},
   "outputs": [],
   "source": [
    "siarl = rio.open(siarl_path) #open SIARL with rasterio\n",
    "siarl_array = siarl.read(1).astype('float64') \n",
    "siarl_array[siarl_array<1.0]=np.nan\n",
    "siarl_affine = siarl.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198dee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class majority calculation for each cell\n",
    "stats_siarl = rstat.zonal_stats(grid, siarl_array, affine=siarl_affine, nodata=128.0, stats=['majority'], categorical=True)\n",
    "majority_list = [{k: v for k, v in d.items() if k == 'majority'} for d in stats_siarl]\n",
    "grid = grid.join(pd.DataFrame(majority_list), how='left')\n",
    "grid = grid.rename(columns={\"majority\": \"siarl\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f2819a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate area fractions for each class in each cell\n",
    "stats_siarl = rstat.zonal_stats(grid, siarl_array, affine=siarl_affine, nodata=128.0, stats=['count'], categorical=True)\n",
    "p = pd.DataFrame.from_dict(stats_siarl, orient='columns')\n",
    "\n",
    "grid.loc[grid.dusaf.notnull(), ['siarl2','siarl9','siarl12']] = 0.0\n",
    "\n",
    "grid['p2'] = p[2.0] / p['count']\n",
    "grid['p9'] = p[9.0] / p['count']\n",
    "grid['p12'] = p[12.0] / p['count']\n",
    "grid.siarl2 = np.nanmax(grid[['siarl2', 'p2']],1)\n",
    "grid.siarl9 = np.nanmax(grid[['siarl9', 'p9']],1)\n",
    "grid.siarl12 = np.nanmax(grid[['siarl12', 'p12']],1)\n",
    "grid = grid.drop(columns=['p2', 'p9', 'p12'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b900cf-c8de-4e39-9d29-b3f1ae1bb2b9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9011a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Soil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f95e87",
   "metadata": {},
   "source": [
    "Information concerning soil and vegetation is also considered, such as:\n",
    "- Soil type: soil classification fron [OpenLandMap USDA Soil Texture classification](https://developers.google.com/earth-engine/datasets/catalog/OpenLandMap_SOL_SOL_TEXTURE-CLASS_USDA-TT_M_v02)\n",
    "- Soil text: soil texture classification obtained from [Carta Pedologica 250k](https://www.geoportale.regione.lombardia.it/metadati?p_p_id=detailSheetMetadata_WAR_gptmetadataportlet&p_p_lifecycle=0&p_p_state=normal&p_p_mode=view&_detailSheetMetadata_WAR_gptmetadataportlet_uuid=%7BA7138B8A-9025-4802-82BC-52267B60A3D7%7D) on Geoportale Regione Lombardia\n",
    "\n",
    "Soil type from Open Land Map - USDA Soil Classification (missing value 3, 10, 11, 12 in this dataset for Lombardy region). Reference system EPSG 32632: \n",
    "- `1` = Clay\n",
    "- `2` = Silty Clay\n",
    "- `3` = Sandy Clay\n",
    "- `4` = Clay Loam\n",
    "- `5` = Silty Clay Loam\n",
    "- `6` = Sandy Clay Loam\n",
    "- `7` = Loam\n",
    "- `8` = Silt Loam\n",
    "- `9` = Sandy Loam\n",
    "- `10` = Silt\n",
    "- `11` = Loamy Sand\n",
    "- `12` = Sand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94d4c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set raster paths\n",
    "soil_type_path = cwd + '/terrain/soil_type.tif'\n",
    "soil_text_path = cwd + '/terrain/carta_pedologica.tif'\n",
    "\n",
    "soil_type = rio.open(soil_type_path)\n",
    "soil_text = rio.open(soil_text_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330ac883",
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_type_array = soil_type.read(1).astype('float64') \n",
    "soil_type_array[soil_type_array<1.0]=np.nan\n",
    "soil_affine = soil_type.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cead2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class majority calculation for each cell\n",
    "stats_soil_type = rstat.zonal_stats(grid, soil_type_array, affine=soil_affine, nodata=255, stats=['majority'], categorical=True)\n",
    "majority_list = [{k: v for k, v in d.items() if k == 'majority'} for d in stats_soil_type]\n",
    "grid = grid.join(pd.DataFrame(majority_list), how='left')\n",
    "grid = grid.rename(columns={\"majority\": \"soil\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d72647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate area fractions for each class in each cell (not existing values for Lombardy region are set as comments)\n",
    "stats_soil = rstat.zonal_stats(grid, soil_type_array, affine=soil_affine, nodata=255, stats=['count'], categorical=True)\n",
    "p = pd.DataFrame.from_dict(stats_soil, orient='columns')\n",
    "\n",
    "grid.loc[grid.dusaf.notnull(), ['soil1','soil2','soil4','soil5','soil7','soil8','soil9']] = 0.0\n",
    "\n",
    "grid['p1'] = p[1.0]/ p['count']\n",
    "grid['p2'] = p[2.0]/ p['count']\n",
    "#grid['p3'] = p[3.0]/ p['count']\n",
    "grid['p4'] = p[4.0]/ p['count']\n",
    "grid['p5'] = p[5.0]/ p['count']\n",
    "#grid['p6'] = p[6.0]/ p['count']\n",
    "grid['p7'] = p[7.0]/ p['count']\n",
    "grid['p8'] = p[8.0]/ p['count']\n",
    "grid['p9'] = p[9.0]/ p['count']\n",
    "#grid['p10'] = p[10.0]/ p['count']\n",
    "#grid['p11'] = p[11.0]/ p['count']\n",
    "#grid['p12'] = p[12.0]/ p['count']\n",
    "\n",
    "grid.soil1 = np.nanmax(grid[['soil1', 'p1']],1)\n",
    "grid.soil2 = np.nanmax(grid[['soil2', 'p2']],1)\n",
    "#grid.soil3 = np.nanmax(grid[['soil3', 'p3']],1)\n",
    "grid.soil4 = np.nanmax(grid[['soil4', 'p4']],1)\n",
    "grid.soil5 = np.nanmax(grid[['soil5', 'p5']],1)\n",
    "#grid.soil6 = np.nanmax(grid[['soil6', 'p6']],1)\n",
    "grid.soil7 = np.nanmax(grid[['soil7', 'p7']],1)\n",
    "grid.soil8 = np.nanmax(grid[['soil8', 'p8']],1)\n",
    "grid.soil9 = np.nanmax(grid[['soil9', 'p9']],1)\n",
    "#grid.soil10 = np.nanmax(grid[['soil10', 'p10']],1)\n",
    "#grid.soil11 = np.nanmax(grid[['soil11', 'p11']],1)\n",
    "#grid.soil12 = np.nanmax(grid[['soil12', 'p12']],1)\n",
    "\n",
    "grid = grid.drop(columns=['p1', 'p2', 'p4', 'p5', 'p7', 'p8', 'p9'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1436c1da",
   "metadata": {},
   "source": [
    "Soil texture categories from Carta Pedologica Regione Lombardia:\n",
    "- `1` = Argillosa fine\n",
    "- `2` = Argillosa molto fine\n",
    "- `3` = Franca fine\n",
    "- `4` = Franca grossolana\n",
    "- `5` = Limosa fine\n",
    "- `6` = Limosa grossolana\n",
    "- `7` = Sabbiosa\n",
    "- `8` = Scheletrico-Argillosa\n",
    "- `9` = Scheletrico-Franca\n",
    "- `10` = Scheletrico-Sabbiosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ae2ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_text_array = soil_text.read(1).astype('float64') \n",
    "soil_text_affine = soil_text.transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86513bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class majority calculation for each cell\n",
    "stats_soil_text = rstat.zonal_stats(grid, soil_text_array, affine=soil_text_affine, nodata=np.nan, stats=['majority'], categorical=True)\n",
    "majority_list = [{k: v for k, v in d.items() if k == 'majority'} for d in stats_soil_text]\n",
    "grid = grid.join(pd.DataFrame(majority_list), how='left')\n",
    "grid = grid.rename(columns={\"majority\": \"soil_text\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4bfcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate area fractions for each class in each cell\n",
    "stats_soil_text = rstat.zonal_stats(grid, soil_text_array, affine=soil_text_affine, nodata=np.nan, stats=['count'], categorical=True)\n",
    "p = pd.DataFrame.from_dict(stats_soil_text, orient='columns')\n",
    "\n",
    "grid.loc[grid.dusaf.notnull(), ['soil_text1','soil_text2','soil_text3','soil_text4',\n",
    "                                  'soil_text5','soil_text6','soil_text7','soil_text8',\n",
    "                                  'soil_text9','soil_text10']] = 0.0\n",
    "\n",
    "grid['p1'] = p[1.0]/ p['count']\n",
    "grid['p2'] = p[2.0]/ p['count']\n",
    "grid['p3'] = p[3.0]/ p['count']\n",
    "grid['p4'] = p[4.0]/ p['count']\n",
    "grid['p5'] = p[5.0]/ p['count']\n",
    "grid['p6'] = p[6.0]/ p['count']\n",
    "grid['p7'] = p[7.0]/ p['count']\n",
    "grid['p8'] = p[8.0]/ p['count']\n",
    "grid['p9'] = p[9.0]/ p['count']\n",
    "grid['p10'] = p[10.0]/ p['count']\n",
    "grid.soil_text1 = np.nanmax(grid[['soil_text1', 'p1']],1)\n",
    "grid.soil_text2 = np.nanmax(grid[['soil_text2', 'p2']],1)\n",
    "grid.soil_text3 = np.nanmax(grid[['soil_text3', 'p3']],1)\n",
    "grid.soil_text4 = np.nanmax(grid[['soil_text4', 'p4']],1)\n",
    "grid.soil_text5 = np.nanmax(grid[['soil_text5', 'p5']],1)\n",
    "grid.soil_text6 = np.nanmax(grid[['soil_text6', 'p6']],1)\n",
    "grid.soil_text7 = np.nanmax(grid[['soil_text7', 'p7']],1)\n",
    "grid.soil_text8 = np.nanmax(grid[['soil_text8', 'p8']],1)\n",
    "grid.soil_text9 = np.nanmax(grid[['soil_text9', 'p9']],1)\n",
    "grid.soil_text10 = np.nanmax(grid[['soil_text10', 'p10']],1)\n",
    "\n",
    "grid = grid.drop(columns=['p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8', 'p9','p10'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6abbb74",
   "metadata": {},
   "source": [
    "### [Road Infrastructures - Geoportale Lombardia (DBTR 2019)](https://www.geoportale.regione.lombardia.it/metadati?p_p_id=detailSheetMetadata_WAR_gptmetadataportlet&p_p_lifecycle=0&p_p_state=normal&p_p_mode=view&_detailSheetMetadata_WAR_gptmetadataportlet_uuid=%7B17D4656F-2E9D-4951-9DC1-4AD32C0959B1%7D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ce0a36",
   "metadata": {},
   "source": [
    "Point layers considered corresponding to road intersections in Lombardy region, specifically:\n",
    " - Intersection between primary roads including highways\n",
    " - Intersection between primary and secondary roads\n",
    " - Intersection between secondary roads\n",
    "\n",
    "Reference system EPSG: 4326."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa4954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "int_prim_path = cwd + '/road_infrastructures/inters_highway_prim_road.gpkg'\n",
    "int_prim_sec_path = cwd + '/road_infrastructures/inters_prim_sec_road.gpkg'\n",
    "int_sec_path = cwd + '/road_infrastructures/inters_sec_road.gpkg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dfe4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the density of road intersections in each cell\n",
    "int_prim = gpd.read_file(int_prim_path).to_crs(32632)  #reproject to 32632\n",
    "int_prim_sec = gpd.read_file(int_prim_sec_path).to_crs(32632) #reproject to 32632\n",
    "int_sec = gpd.read_file(int_sec_path).to_crs(32632) #reproject to 32632\n",
    "\n",
    "df_dict = {'int_prim':int_prim,\n",
    "          'int_prim_sec':int_prim_sec, 'int_sec': int_sec}\n",
    "\n",
    "for key in df_dict:\n",
    "    poor_points = df_dict[key][['OBJECTID','geometry']]\n",
    "    sjoined = gpd.sjoin(poor_points, grid)\n",
    "    df_count = pd.DataFrame(sjoined.groupby('index_right').size()) \n",
    "    grid_join = grid.join(df_count)\n",
    "    grid[key] = grid_join[0]\n",
    "    print(\"Added column: \",key)\n",
    "\n",
    "grid.int_prim[np.isnan(grid.int_prim)] = 0.0   \n",
    "grid.int_prim_sec[np.isnan(grid.int_prim_sec)] = 0.0   \n",
    "grid.int_sec[np.isnan(grid.int_sec)] = 0.0   \n",
    "grid.loc[grid.dusaf.isnull(), ['int_prim','int_prim_sec','int_sec']] = np.nan   \n",
    "grid['int_prim'] = grid['int_prim'] / grid['area']\n",
    "grid['int_prim_sec'] = grid['int_prim_sec'] / grid['area']\n",
    "grid['int_sec'] = grid['int_sec'] / grid['area']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b2bbad",
   "metadata": {},
   "source": [
    "Roads are also considered, specifically:\n",
    " - Highways\n",
    " - Primary roads\n",
    " - Secondary roads\n",
    "\n",
    "Reference system EPSG: 4326"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3982ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "highway_path = cwd + '/road_infrastructures/highway.gpkg'\n",
    "prim_road_path = cwd + '/road_infrastructures/prim_road.gpkg'\n",
    "sec_road_path = cwd + '/road_infrastructures/sec_road.gpkg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f090893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the road density in each cell\n",
    "highway = gpd.read_file(highway_path).to_crs(32632) #reproject to 32632\n",
    "prim_road = gpd.read_file(prim_road_path).to_crs(32632) #reproject to 32632\n",
    "sec_road = gpd.read_file(sec_road_path).to_crs(32632) #reproject to 32632\n",
    "\n",
    "df_dict = {'highway':highway, 'prim_road':prim_road, 'sec_road':sec_road}\n",
    "\n",
    "for key in df_dict:\n",
    "    grid[key] = np.nan\n",
    "    poor_lines = df_dict[key][['geodb_oid','geometry']]\n",
    "    for index, row in grid.iterrows():\n",
    "        mask = row['geometry']\n",
    "        clip = gpd.clip(poor_lines, mask) \n",
    "        l = clip.geometry.length.sum()\n",
    "        grid[key].iloc[index] = l*m_to_km\n",
    "    print(\"Added column: \",key)\n",
    "\n",
    "grid.highway[np.isnan(grid.highway)] = 0.0   \n",
    "grid.prim_road[np.isnan(grid.prim_road)] = 0.0   \n",
    "grid.sec_road[np.isnan(grid.sec_road)] = 0.0   \n",
    "grid.loc[grid.dusaf.isnull(), ['highway','prim_road','sec_road']] = np.nan  \n",
    "grid['highway'] = grid['highway'] / grid['area']\n",
    "grid['prim_road'] = grid['prim_road'] / grid['area']\n",
    "grid['sec_road'] = grid['sec_road'] / grid['area']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b386ff5e",
   "metadata": {},
   "source": [
    " - - -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8880917",
   "metadata": {},
   "source": [
    "### Farms\n",
    "Vector file obtained from DUSAF 2018 (features with cod. 12112 = \"Agricultural production settlements.\n",
    "This class includes buildings used for productive activities in the primary sector, such as sheds, machine sheds, barns, stables, silos, etc., together with accessory spaces. When these buildings are present together with residential buildings, forming a rural aggregate, if the two types cannot be clearly separated, the whole nucleus is classified as a farmstead (11231)\"). Reference system EPSG:32632."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7f63bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set path\n",
    "farms_path = cwd + '/farms/farms_dissolve.gpkg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1bec4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate farms area % in each cell\n",
    "farms = gpd.read_file(farms_path)\n",
    "\n",
    "df_dict2 = {'farms':farms}\n",
    "\n",
    "for key in df_dict2:\n",
    "    grid[key] = np.nan\n",
    "    poor_poly = df_dict2[key][['COD_TOT','geometry']]\n",
    "    for index, row in grid.iterrows():\n",
    "        mask = row['geometry']\n",
    "        clip = gpd.clip(poor_poly, mask) \n",
    "        a = clip.geometry.area.sum()\n",
    "        grid[key].iloc[index] = a*m2_to_km2\n",
    "    print(\"Added column: \", key)\n",
    "    \n",
    "grid.farms[np.isnan(grid.farms)] = 0.0   \n",
    "grid.loc[grid.dusaf.isnull(), ['farms']] = np.nan  \n",
    "grid['farms'] = grid['farms']/ grid['area']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe1ae27",
   "metadata": {},
   "source": [
    "### Breeding farm type\n",
    "\n",
    "Breeding farm types available:\n",
    " - Pigs\n",
    " - Poultry\n",
    " - Sheeps\n",
    "\n",
    "Reference system EPSG: 4326."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc3e43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "pigs_path = cwd + '/farms/pigs.gpkg'\n",
    "poultry_path = cwd + '/farms/poultry.gpkg'\n",
    "sheep_path = cwd + '/farms/sheep.gpkg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ffb704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate density for each farm type in each cell\n",
    "farm_pigs = gpd.read_file(pigs_path).to_crs(32632) #reproject to 32632\n",
    "farm_poultry = gpd.read_file(poultry_path).to_crs(32632) #reproject to 32632\n",
    "farm_sheep = gpd.read_file(sheep_path).to_crs(32632) #reproject to 32632\n",
    "\n",
    "df_dict = {'farm_pigs':farm_pigs,\n",
    "          'farm_poultry':farm_poultry, 'farm_sheep':farm_sheep}\n",
    "\n",
    "for key in df_dict:\n",
    "    poor_points = df_dict[key][['OBJECTID','geometry']]\n",
    "    sjoined = gpd.sjoin(poor_points, grid)\n",
    "    df_count = pd.DataFrame(sjoined.groupby('index_right').size()) \n",
    "    grid_join = grid.join(df_count)\n",
    "    grid[key] = grid_join[0]\n",
    "    print(key)\n",
    "    \n",
    "grid.farm_pigs[np.isnan(grid.farm_pigs)] = 0.0   \n",
    "grid.farm_poultry[np.isnan(grid.farm_poultry)] = 0.0   \n",
    "grid.farm_sheep[np.isnan(grid.farm_sheep)] = 0.0   \n",
    "grid.loc[grid.dusaf.isnull(), ['farm_pigs','farm_poultry','farm_sheep']] = np.nan   \n",
    "grid['farm_pigs'] = grid['farm_pigs']/ grid['area']\n",
    "grid['farm_poultry'] = grid['farm_poultry']/ grid['area']\n",
    "grid['farm_sheep'] = grid['farm_sheep']/ grid['area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cb453e-e551-44e7-8017-55a1cead3694",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = grid.to_crs(4326)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cdc364",
   "metadata": {},
   "source": [
    "Create grid with Map Layers already preprocessed to avoid calculation with the same data. It will be automatically saved using the grid resolution name and adding the \"_prep\" to specify that the grid contains preprocessed data already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6170df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Grid will be save as: grid_'+str(name.value)+'_prep.gpkg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c933f27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.to_crs(4326).to_file(cwd+\"/grid/\"+'grid_'+str(name.value)+\"_prep.gpkg\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb8fb9d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb9d27e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Satellite - Model - Ground Sensor Data Processing <a id='not-map-layers'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93db235",
   "metadata": {},
   "source": [
    "In this section satellite, model and ground sensor data previously downloaded with the other notebooks are imported, and processed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babb5a27",
   "metadata": {},
   "source": [
    "Import the already processed Map Layers version of the grid (\"_prep\" tag):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7627050d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = gpd.read_file(cwd +\"/grid/\"+'grid_'+str(name.value)+\"_prep.gpkg\") #Read the grid with Map Layer already processed\n",
    "print('Imported grid: grid_'+str(name.value)+'_prep.gpkg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fad3cec",
   "metadata": {},
   "source": [
    "### NDVI \n",
    "NDVI obtained from [Terra Vegetation Indices 16-Day Global 250m dataset](https://developers.google.com/earth-engine/datasets/catalog/MODIS_006_MOD13Q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724d762b",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Set path\n",
    "ndvi_path = cwd + '/temp/ndvi.tif'\n",
    "ndvi = rio.open(ndvi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd43a580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate mean NDVI value in each cell\n",
    "ndvi_array = ndvi.read(1)\n",
    "affine = ndvi.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, ndvi_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"ndvi\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7744545b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fbed27",
   "metadata": {},
   "source": [
    "### ECMWF - C3S ERA5 Model Meteorological data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a37245",
   "metadata": {},
   "source": [
    "Meteorological data are obtained from [ERA5 - Land Hourly Reanalysis](https://developers.google.com/earth-engine/datasets/catalog/ECMWF_ERA5_LAND_HOURLY).\n",
    "The variables considered are: \n",
    " - Temperature\n",
    " - Precipitation\n",
    " - Atmospheric pressure\n",
    " - Wind speed (eastward and northward components)\n",
    " - Soil water content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6db859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "temp_2m_path = cwd + '/temp/temp_2m.tif'\n",
    "prec_path = cwd + '/temp/prec.tif'\n",
    "press_path = cwd + '/temp/press.tif'\n",
    "n_wind_path = cwd + '/temp/n_wind.tif'\n",
    "e_wind_path = cwd + '/temp/e_wind.tif'\n",
    "soil_moist_path = cwd + '/temp/soil_hum.tif'\n",
    "\n",
    "temp_2m = rio.open(temp_2m_path)\n",
    "prec = rio.open(prec_path)\n",
    "press = rio.open(press_path)\n",
    "n_wind = rio.open(n_wind_path)\n",
    "e_wind = rio.open(e_wind_path)\n",
    "soil_moist = rio.open(soil_moist_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1082654-95b4-44ef-bd14-9fe2ec6419ec",
   "metadata": {},
   "source": [
    "Calculate the mean value for each data in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f694798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_2m_array = temp_2m.read(1)\n",
    "affine = temp_2m.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, temp_2m_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"temp_2m\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7232c6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_array = prec.read(1)\n",
    "prec_array[prec_array<0]=np.nan\n",
    "affine = prec.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, prec_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"prec\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2f787b",
   "metadata": {},
   "outputs": [],
   "source": [
    "press_array = press.read(1)\n",
    "press_array[press_array<0]=np.nan\n",
    "affine = press.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, press_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"press\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfe3ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_wind_array = n_wind.read(1)\n",
    "affine = n_wind.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, n_wind_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"n_wind\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a9930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_wind_array = e_wind.read(1)\n",
    "affine = e_wind.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, e_wind_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"e_wind\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcc6619-da07-42b0-b65a-072e81159abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "soil_moist_array = soil_moist.read(1)\n",
    "soil_moist_array[soil_moist_array<0]=np.nan\n",
    "affine = soil_moist.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, soil_moist_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"soil_moist\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20540936",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import pollutants data\n",
    "\n",
    "Importing pollutants data from:\n",
    "- Sentinel-5P Tropomi instrument and Terra&Aqua MODIS.\n",
    "- Copernicus Atmosphere Monitoring Service (CAMS) European Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325b17e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From Sentinel-5P Tropomi and Terra&Aqua MODIS\n",
    "no2_path = cwd + '/temp/no2_s5p.tif'\n",
    "so2_path = cwd + '/temp/so2_s5p.tif'\n",
    "aod55_path = cwd + '/temp/aod_055.tif'\n",
    "aod47_path = cwd + '/temp/aod_047.tif'\n",
    "uvai_path = cwd + '/temp/uvai_s5p.tif'\n",
    "co_path = cwd + '/temp/co_s5p.tif'\n",
    "ch2o_path = cwd + '/temp/ch2o_s5p.tif'\n",
    "o3_path = cwd + '/temp/o3_s5p.tif'\n",
    "ch4_path = cwd + '/temp/ch4_s5p.tif'\n",
    "\n",
    "no2 = rio.open(no2_path)\n",
    "so2 = rio.open(so2_path)\n",
    "aod55 = rio.open(aod55_path)\n",
    "aod47 = rio.open(aod47_path)\n",
    "uvai = rio.open(uvai_path)\n",
    "co = rio.open(co_path)\n",
    "ch2o = rio.open(ch2o_path)\n",
    "o3 = rio.open(o3_path)\n",
    "ch4 = rio.open(ch4_path)\n",
    "#------------------------\n",
    "#From CAMS\n",
    "nh3_cams_path = cwd + '/temp/nh3_cams.nc'\n",
    "no_cams_path = cwd + '/temp/no_cams.nc'\n",
    "co_cams_path = cwd + '/temp/co_cams.nc'\n",
    "no2_cams_path = cwd + '/temp/no2_cams.nc'\n",
    "dust_cams_path = cwd + '/temp/dust_cams.nc'\n",
    "pm10_cams_path = cwd + '/temp/pm10_cams.nc'\n",
    "pm25_cams_path = cwd + '/temp/pm25_cams.nc'\n",
    "nmvocs_cams_path = cwd + '/temp/nmvocs_cams.nc'\n",
    "so2_cams_path = cwd + '/temp/so2_cams.nc'\n",
    "o3_cams_path = cwd + '/temp/o3_cams.nc'\n",
    "\n",
    "nh3_cams = rioxarray.open_rasterio(nh3_cams_path,masked=True).rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "no_cams = rioxarray.open_rasterio(no_cams_path,masked=True).rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "co_cams = rioxarray.open_rasterio(co_cams_path,masked=True).rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "no2_cams = rioxarray.open_rasterio(no2_cams_path,masked=True).rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "dust_cams = rioxarray.open_rasterio(dust_cams_path,masked=True).rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "pm10_cams = rioxarray.open_rasterio(pm10_cams_path,masked=True).rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "pm25_cams = rioxarray.open_rasterio(pm25_cams_path,masked=True).rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "nmvocs_cams = rioxarray.open_rasterio(nmvocs_cams_path,masked=True).rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "so2_cams = rioxarray.open_rasterio(so2_cams_path,masked=True).rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "o3_cams = rioxarray.open_rasterio(o3_cams_path,masked=True).rio.write_crs(\"epsg:4326\", inplace=True)\n",
    "\n",
    "#Convert nh3 to .tif\n",
    "nh3_cams.rio.to_raster(cwd + \"/temp/nh3_cams.tif\")\n",
    "nh3_cams_path = cwd + '/temp/nh3_cams.tif'\n",
    "nh3_cams = rio.open(nh3_cams_path)\n",
    "#Convert NO to .tif\n",
    "no_cams.rio.to_raster(cwd + \"/temp/no_cams.tif\")\n",
    "no_cams_path = cwd + '/temp/no_cams.tif'\n",
    "no_cams = rio.open(no_cams_path)\n",
    "#Convert CO to .tif\n",
    "co_cams.rio.to_raster(cwd + \"/temp/co_cams.tif\")\n",
    "co_cams_path = cwd + '/temp/co_cams.tif'\n",
    "co_cams = rio.open(co_cams_path)\n",
    "#Convert dust to .tif\n",
    "dust_cams.rio.to_raster(cwd + \"/temp/dust_cams.tif\")\n",
    "dust_cams_path = cwd + '/temp/dust_cams.tif'\n",
    "dust_cams = rio.open(dust_cams_path)\n",
    "#Convert PM10 to .tif\n",
    "pm10_cams.rio.to_raster(cwd + \"/temp/pm10_cams.tif\")\n",
    "pm10_cams_path = cwd + '/temp/pm10_cams.tif'\n",
    "pm10_cams = rio.open(pm10_cams_path)\n",
    "#Convert PM25 to .tif\n",
    "pm25_cams.rio.to_raster(cwd + \"/temp/pm25_cams.tif\")\n",
    "pm25_cams_path = cwd + '/temp/pm25_cams.tif'\n",
    "pm25_cams = rio.open(pm25_cams_path)\n",
    "#Convert NO2 to .tif\n",
    "no2_cams.rio.to_raster(cwd + \"/temp/no2_cams.tif\")\n",
    "no2_cams_path = cwd + '/temp/no2_cams.tif'\n",
    "no2_cams = rio.open(no2_cams_path)\n",
    "#Convert NMVOCs to .tif\n",
    "nmvocs_cams.rio.to_raster(cwd + \"/temp/nmvocs_cams.tif\")\n",
    "nmvocs_cams_path = cwd + '/temp/nmvocs_cams.tif'\n",
    "nmvocs_cams = rio.open(nmvocs_cams_path)\n",
    "#Convert SO2 to .tif\n",
    "so2_cams.rio.to_raster(cwd + \"/temp/so2_cams.tif\")\n",
    "so2_cams_path = cwd + '/temp/so2_cams.tif'\n",
    "so2_cams = rio.open(so2_cams_path)\n",
    "#Convert o3 to .tif\n",
    "o3_cams.rio.to_raster(cwd + \"/temp/o3_cams.tif\")\n",
    "o3_cams_path = cwd + '/temp/o3_cams.tif'\n",
    "o3_cams = rio.open(o3_cams_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6e27fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Satellite Pollutants Data Processing\n",
    "Calculate mean values for each cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24512325",
   "metadata": {},
   "outputs": [],
   "source": [
    "no2_array = no2.read(1)\n",
    "no2_array[no2_array<=0]=np.nan\n",
    "affine = no2.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, no2_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"no2_s5p\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7659d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "so2_array = so2.read(1)\n",
    "so2_array[so2_array<=0]=np.nan\n",
    "affine = so2.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, so2_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"so2_s5p\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15202a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "aod55_array = aod55.read(1)\n",
    "aod55_array[aod55_array<=0]=np.nan\n",
    "affine = aod55.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, aod55_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"aod_055\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5477913",
   "metadata": {},
   "outputs": [],
   "source": [
    "aod47_array = aod47.read(1)\n",
    "aod55_array[aod55_array<=0]=np.nan\n",
    "affine = aod47.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, aod47_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"aod_047\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f2d138",
   "metadata": {},
   "outputs": [],
   "source": [
    "uvai_array = uvai.read(1)\n",
    "affine = uvai.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, uvai_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"uvai\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca91553",
   "metadata": {},
   "outputs": [],
   "source": [
    "co_array = co.read(1)\n",
    "co_array[co_array<=0]=np.nan\n",
    "affine = co.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, co_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"co_s5p\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0853c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch2o_array = ch2o.read(1)\n",
    "ch2o_array[ch2o_array<=0]=np.nan\n",
    "affine = ch2o.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, ch2o_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"ch2o_s5p\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370d8436",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3_array = o3.read(1)\n",
    "o3_array[o3_array<=0]=np.nan\n",
    "affine = o3.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, o3_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"o3_s5p\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9e0e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch4_array = ch4.read(1)\n",
    "ch4_array[ch4_array<=0]=np.nan\n",
    "affine = ch4.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, ch4_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"ch4_s5p\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e69c1e",
   "metadata": {},
   "source": [
    "### CAMS Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6a1d38",
   "metadata": {},
   "source": [
    "Reading satellite .tif files and calculating mean values for each cell. <br>\n",
    "CAMS data are provided with an original resolution of 0.1°. When the 0.1° resolution grid is selected, the upscale_factor is set to 1 and the data keep the original resolution.\n",
    "When a grid with a higher resolution is selected (0.066° or 0.01°) CAMS data are resampled using bilinear interpolation to a higher resolution (upscale_factor defined at the beginning of the notebook, higher than 1). This procedure is not applied for other data because they are already resampled to a higher resolution when downloaded (e.g. Google Earth Engine API allows to set a higher resolution when exporting data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34074a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample CAMS data and save them with \"_cams_upsampled\" tag\n",
    "for files in os.listdir(cwd+'/temp'):\n",
    "    if files[-9:] == '_cams.tif':\n",
    "        file_name = files[:(len(files)-9)]\n",
    "        xds = rioxarray.open_rasterio(cwd + \"/temp/\"+files,masked=True)\n",
    "        new_width = xds.rio.width * upscale_factor\n",
    "        new_height = xds.rio.height * upscale_factor\n",
    "        xds_upsampled = xds.rio.reproject(xds.rio.crs,shape=(new_height, new_width),resampling=Resampling.bilinear)\n",
    "        xds_upsampled.rio.to_raster(cwd +'/temp/'+file_name+'_cams_upsampled.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1c0ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAMS data\n",
    "nh3_cams_path = cwd + '/temp/nh3_cams_upsampled.tif'\n",
    "nh3_cams = rio.open(nh3_cams_path)\n",
    "\n",
    "no_cams_path = cwd + '/temp/no_cams_upsampled.tif'\n",
    "no_cams = rio.open(no_cams_path)\n",
    "\n",
    "co_cams_path = cwd + '/temp/co_cams_upsampled.tif'\n",
    "co_cams = rio.open(co_cams_path)\n",
    "\n",
    "dust_cams_path = cwd + '/temp/dust_cams_upsampled.tif'\n",
    "dust_cams = rio.open(dust_cams_path)\n",
    "\n",
    "pm10_cams_path = cwd + '/temp/pm10_cams_upsampled.tif'\n",
    "pm10_cams = rio.open(pm10_cams_path)\n",
    "\n",
    "pm25_cams_path = cwd + '/temp/pm25_cams_upsampled.tif'\n",
    "pm25_cams = rio.open(pm25_cams_path)\n",
    "\n",
    "no2_cams_path = cwd + '/temp/no2_cams_upsampled.tif'\n",
    "no2_cams = rio.open(no2_cams_path)\n",
    "\n",
    "nmvocs_cams_path = cwd + '/temp/nmvocs_cams_upsampled.tif'\n",
    "nmvocs_cams = rio.open(nmvocs_cams_path)\n",
    "\n",
    "so2_cams_path = cwd + '/temp/so2_cams_upsampled.tif'\n",
    "so2_cams = rio.open(so2_cams_path)\n",
    "\n",
    "o3_cams_path = cwd + '/temp/o3_cams_upsampled.tif'\n",
    "o3_cams = rio.open(o3_cams_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938a790c-b767-4f00-88f5-84a081ced0db",
   "metadata": {},
   "source": [
    "Calculate mean values for each cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8023f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "nh3_cams_array = nh3_cams.read(1)\n",
    "nh3_cams_array[nh3_cams_array<0]=np.nan\n",
    "affine = nh3_cams.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, nh3_cams_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"nh3_cams\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211549e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cams_array = no_cams.read(1)\n",
    "no_cams_array[no_cams_array<0]=np.nan\n",
    "affine = no_cams.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, no_cams_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"no_cams\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cbfb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "co_cams_array = co_cams.read(1)\n",
    "co_cams_array[co_cams_array<0]=np.nan\n",
    "affine = co_cams.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, co_cams_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"co_cams\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea7ecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dust_cams_array = dust_cams.read(1)\n",
    "dust_cams_array[dust_cams_array<0]=np.nan\n",
    "affine = dust_cams.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, dust_cams_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"dust_cams\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f04d04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm10_cams_array = pm10_cams.read(1)\n",
    "pm10_cams_array[pm10_cams_array<0]=np.nan\n",
    "affine = pm10_cams.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, pm10_cams_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"pm10_cams\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99060c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_cams_array = pm25_cams.read(1)\n",
    "pm25_cams_array[pm25_cams_array<0]=np.nan\n",
    "affine = pm25_cams.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, pm25_cams_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"pm25_cams\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ba7aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "no2_cams_array = no2_cams.read(1)\n",
    "no2_cams_array[no2_cams_array<0]=np.nan\n",
    "affine = no2_cams.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, no2_cams_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"no2_cams\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184073b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmvocs_cams_array = nmvocs_cams.read(1)\n",
    "nmvocs_cams_array[nmvocs_cams_array<0]=np.nan\n",
    "affine = nmvocs_cams.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, nmvocs_cams_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"nmvocs_cams\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234c1dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "so2_cams_array = so2_cams.read(1)\n",
    "so2_cams_array[so2_cams_array<0]=np.nan\n",
    "affine = so2_cams.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, so2_cams_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"so2_cams\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c43d822",
   "metadata": {},
   "outputs": [],
   "source": [
    "o3_cams_array = o3_cams.read(1)\n",
    "o3_cams_array[o3_cams_array<0]=np.nan\n",
    "affine = o3_cams.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, o3_cams_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"o3_cams\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3df332d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe26885",
   "metadata": {},
   "source": [
    "### ARPA Meteorological Ground Sensors Processing\n",
    "Importing multipoint geometry, where each point contains mean values for each sensor type:\n",
    "- Temperature\n",
    "- Precipitation\n",
    "- Air humidity\n",
    "- Wind direction\n",
    "- Wind speed\n",
    "- Global radiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d5a4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_st_path = cwd + '/temp/temp_st.gpkg'\n",
    "prec_st_path = cwd + '/temp/prec_st.gpkg'\n",
    "air_hum_st_path = cwd + '/temp/air_hum_st.gpkg'\n",
    "wind_dir_st_path = cwd + '/temp/wind_dir_st.gpkg'\n",
    "wind_speed_st_path = cwd + '/temp/wind_speed_st.gpkg'\n",
    "rad_glob_st_path = cwd + '/temp/rad_glob_st.gpkg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda99bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_st = gpd.read_file(temp_st_path)\n",
    "prec_st = gpd.read_file(prec_st_path)\n",
    "air_hum_st = gpd.read_file(air_hum_st_path)\n",
    "wind_dir_st = gpd.read_file(wind_dir_st_path)\n",
    "wind_speed_st = gpd.read_file(wind_speed_st_path)\n",
    "rad_glob_st = gpd.read_file(rad_glob_st_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b7b1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {'temp_st':temp_st,\n",
    "          'prec_st':prec_st, 'air_hum_st': air_hum_st, 'wind_speed_st':wind_speed_st,\n",
    "          'rad_glob_st':rad_glob_st}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2d0386",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in df_dict:\n",
    "    grid[key] = np.nan\n",
    "    poor_points = df_dict[key][['idsensore','valore','geometry']]\n",
    "    for index, row in grid.iterrows():\n",
    "        mask = row['geometry']\n",
    "        if grid['aq_zone'].iloc[index] > 0:\n",
    "            clip = gpd.clip(poor_points, mask)\n",
    "            m = clip.valore.mean()\n",
    "            grid[key].iloc[index] = m\n",
    "    print(\"Added column: \", key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dd7e9c-651d-4ecc-8b42-78a9cb4894bc",
   "metadata": {},
   "source": [
    "For wind direction the point category is assigned to the cell. If multiple points are inside the cell one value is selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6934a123-57d7-4d33-a2ab-d8f3404e0a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {'wind_dir_st':wind_dir_st}\n",
    "\n",
    "for key in df_dict:\n",
    "    grid[key] = np.nan\n",
    "    poor_points = df_dict[key][['idsensore','valore','geometry']]\n",
    "    for index, row in grid.iterrows():\n",
    "        mask = row['geometry']\n",
    "        if grid['aq_zone'].iloc[index] > 0:\n",
    "            clip = gpd.clip(poor_points, mask)\n",
    "            m = clip['valore'].max()   #which choose between multiple sensors in the same cell?\n",
    "            grid[key].iloc[index] = m\n",
    "    print(\"Added column: \", key) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57881cb3",
   "metadata": {},
   "source": [
    "### ARPA Air Quality Ground Sensor Processing\n",
    "Importing multipoint geometry, where each point contains mean values for each sensor type:\n",
    "- PM2.5\n",
    "- NOx\n",
    "- NO2\n",
    "- NH3\n",
    "- SO2\n",
    "- PM10\n",
    "- CO\n",
    "- O3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87185d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_st_path = cwd + '/temp/pm25_st.gpkg'\n",
    "nox_st_path = cwd + '/temp/nox_st.gpkg'\n",
    "no2_st_path = cwd + '/temp/no2_st.gpkg'\n",
    "nh3_st_path = cwd + '/temp/nh3_st.gpkg'\n",
    "so2_st_path = cwd + '/temp/so2_st.gpkg'\n",
    "pm10_st_path = cwd + '/temp/pm10_st.gpkg'\n",
    "co_st_path = cwd + '/temp/co_st.gpkg'\n",
    "o3_st_path = cwd + '/temp/o3_st.gpkg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268a0e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_st = gpd.read_file(pm25_st_path)\n",
    "nox_st = gpd.read_file(nox_st_path)\n",
    "no2_st = gpd.read_file(no2_st_path)\n",
    "nh3_st = gpd.read_file(nh3_st_path)\n",
    "so2_st = gpd.read_file(so2_st_path)\n",
    "pm10_st = gpd.read_file(pm10_st_path)\n",
    "co_st = gpd.read_file(co_st_path)\n",
    "o3_st = gpd.read_file(o3_st_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ec521a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {'pm25_st':pm25_st,\n",
    "          'nox_st':nox_st, 'no2_st': no2_st,'o3_st':o3_st, 'nh3_st':nh3_st, 'so2_st':so2_st, 'pm10_st':pm10_st, 'co_st':co_st}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90efa965",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in df_dict:\n",
    "    grid[key] = 0\n",
    "    poor_points = df_dict[key][['idsensore','valore','geometry']]\n",
    "    for index, row in grid.iterrows():\n",
    "        if grid['aq_zone'].iloc[index] > 0:\n",
    "            mask = row['geometry']\n",
    "            clip = gpd.clip(poor_points, mask) \n",
    "            m = clip.valore.mean()\n",
    "            grid[key].iloc[index] = m\n",
    "    print(\"Added column: \", key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc862760",
   "metadata": {},
   "source": [
    "### [ESA Air Quality Sensors Data Processing](https://aqp.eo.esa.int/map/) \n",
    "Importing multipoint geometry, where each point contains mean values for each sensor type:\n",
    "- PM2.5\n",
    "- PM10\n",
    "- NH3\n",
    "- NO2\n",
    "- CO2\n",
    "- CO\n",
    "- Air Humidity\n",
    "- Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ffdd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_lcs_path = cwd + '/temp/pm25_lcs.gpkg'\n",
    "pm10_lcs_path = cwd + '/temp/pm10_lcs.gpkg'\n",
    "hum_lcs_path = cwd + '/temp/hum_lcs.gpkg'\n",
    "temp_lcs_path = cwd + '/temp/temp_lcs.gpkg'\n",
    "no2_lcs_path = cwd + '/temp/no2_lcs.gpkg'\n",
    "co2_lcs_path = cwd + '/temp/co2_lcs.gpkg'\n",
    "nh3_lcs_path = cwd + '/temp/nh3_lcs.gpkg'\n",
    "co_lcs_path = cwd + '/temp/co_lcs.gpkg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36385537",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm25_lcs = gpd.read_file(pm25_lcs_path)\n",
    "pm10_lcs = gpd.read_file(pm10_lcs_path)\n",
    "hum_lcs = gpd.read_file(hum_lcs_path)\n",
    "temp_lcs = gpd.read_file(temp_lcs_path)\n",
    "no2_lcs = gpd.read_file(no2_lcs_path)\n",
    "co2_lcs = gpd.read_file(co2_lcs_path)\n",
    "nh3_lcs = gpd.read_file(nh3_lcs_path)\n",
    "co_lcs = gpd.read_file(co_lcs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4e98c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = {'pm25_lcs':pm25_lcs,\n",
    "          'pm10_lcs':pm10_lcs, 'hum_lcs': hum_lcs, 'temp_lcs':temp_lcs, 'no2_lcs':no2_lcs,\n",
    "          'co2_lcs':co2_lcs, 'nh3_lcs':nh3_lcs, 'co_lcs':co_lcs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beddd7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in df_dict:\n",
    "    grid[key] = 0\n",
    "    poor_points = df_dict[key][['device_id','value','geometry']]\n",
    "    for index, row in grid.iterrows():\n",
    "        if grid['aq_zone'].iloc[index] > 0:\n",
    "            mask = row['geometry']\n",
    "            clip = gpd.clip(poor_points, mask) \n",
    "            m = clip.value.mean()\n",
    "            grid[key].iloc[index] = m\n",
    "    print(\"Added column: \", key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1501367c",
   "metadata": {},
   "source": [
    "### Air Quality Ground Sensor Interpolated Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ccd23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change crs to match interpolated .tif files\n",
    "grid = grid.to_crs(32632)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9324bdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "int_co_path = cwd + '/temp/int_co.tif'\n",
    "int_nh3_path = cwd + '/temp/int_nh3.tif'\n",
    "int_no2_path = cwd + '/temp/int_no2.tif'\n",
    "int_nox_path = cwd + '/temp/int_nox.tif'\n",
    "int_o3_path = cwd + '/temp/int_o3.tif'\n",
    "int_pm10_path = cwd + '/temp/int_pm10.tif'\n",
    "int_pm25_path = cwd + '/temp/int_pm25.tif'\n",
    "int_so2_path = cwd + '/temp/int_so2.tif'\n",
    "\n",
    "int_co = rio.open(int_co_path)\n",
    "int_nh3 = rio.open(int_nh3_path)\n",
    "int_no2 = rio.open(int_no2_path)\n",
    "int_nox = rio.open(int_nox_path)\n",
    "int_o3 = rio.open(int_o3_path)\n",
    "int_pm10 = rio.open(int_pm10_path)\n",
    "int_pm25 = rio.open(int_pm25_path)\n",
    "int_so2 = rio.open(int_so2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72eddb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_co_array = int_co.read(1).astype('float64') \n",
    "affine = int_co.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, int_co_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"co_int\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65014e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_nh3_array = int_nh3.read(1).astype('float64') \n",
    "affine = int_nh3.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, int_nh3_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"nh3_int\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1fba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_no2_array = int_no2.read(1).astype('float64') \n",
    "affine = int_no2.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, int_no2_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"no2_int\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe47f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_nox_array = int_nox.read(1).astype('float64') \n",
    "affine = int_nox.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, int_nox_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"nox_int\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e020ca4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_o3_array = int_o3.read(1).astype('float64') \n",
    "affine = int_o3.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, int_o3_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"o3_int\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0bde1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_pm10_array = int_pm10.read(1).astype('float64') \n",
    "affine = int_pm10.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, int_pm10_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"pm10_int\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92e6b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_pm25_array = int_pm25.read(1).astype('float64') \n",
    "affine = int_pm25.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, int_pm25_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"pm25_int\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6669592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_so2_array = int_so2.read(1).astype('float64') \n",
    "affine = int_so2.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, int_so2_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"so2_int\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4145fdd",
   "metadata": {},
   "source": [
    "### Meteorological Ground Sensor Interpolated Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2608ef7",
   "metadata": {},
   "source": [
    "In order to get continuous data over the Lombardy region, interpolated ground sensor data are used. For precipitation data, interpolated values below 0 mm/h are set to 0 mm/h."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c125238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "int_air_hum_path = cwd + '/temp/int_air_hum.tif'\n",
    "int_prec_path = cwd + '/temp/int_prec.tif'\n",
    "int_rad_glob_path = cwd + '/temp/int_rad_glob.tif'\n",
    "int_temp_path = cwd + '/temp/int_temp.tif'\n",
    "int_wind_speed_path = cwd + '/temp/int_wind_speed.tif'\n",
    "\n",
    "\n",
    "int_air_hum = rio.open(int_air_hum_path)\n",
    "int_prec = rio.open(int_prec_path)\n",
    "int_rad_glob = rio.open(int_rad_glob_path)\n",
    "int_temp = rio.open(int_temp_path)\n",
    "int_wind_speed = rio.open(int_wind_speed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5166b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_air_hum_array = int_air_hum.read(1).astype('float64') \n",
    "affine = int_air_hum.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, int_air_hum_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"air_hum_int\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658464a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_prec_array = int_prec.read(1).astype('float64') \n",
    "int_prec_array[int_prec_array<0]=0  #set values to 0 if interpolation is negative\n",
    "affine = int_prec.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, int_prec_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"prec_int\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5385ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_rad_glob_array = int_rad_glob.read(1).astype('float64') \n",
    "affine = int_rad_glob.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, int_rad_glob_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"rad_glob_int\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878b0a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_temp_array = int_temp.read(1).astype('float64') \n",
    "affine = int_temp.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, int_temp_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"temp_int\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb65962",
   "metadata": {},
   "outputs": [],
   "source": [
    "int_wind_speed_array = int_wind_speed.read(1).astype('float64') \n",
    "affine = int_wind_speed.transform\n",
    "grid = grid.join(pd.DataFrame(rstat.zonal_stats(grid, int_wind_speed_array, affine=affine, nodata=np.nan, stats=['mean'])), how='left')\n",
    "grid = grid.rename(columns={\"mean\": \"wind_speed_int\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cb45f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## File export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef79c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_list = list(grid) #list of the columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6805844b",
   "metadata": {},
   "source": [
    "Grid name: for example grid_0_01_0310_0317_2021 corresponds to the grid with:\n",
    "- Grid resolution of 0.01°\n",
    "- Start and end date (mmdd) for which the average are calculated (for example 0310 is March 10th and 0317 is March 17th). \n",
    "- 2021 year of calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9225aace-6e07-4b42-bb1a-1f1f3e7ea001",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_notna = grid[grid['aq_zone'].notna()]  #remove rows where aq_zone is nan (outside lombardy region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090b0d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_name = ''.join(str(i)+'_' for i in custom_week).replace('-','')\n",
    "date_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2bbced",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_name = 'grid_'+str(name.value)+'_'+date_name.replace('-','')+str(year)\n",
    "print(\"The exported file name: \", grid_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5d0320",
   "metadata": {},
   "source": [
    "Export the file with WGS84 CRS setting the grid name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff491b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_notna.to_crs(4326).to_file(cwd+\"/results/\"+grid_name+\".gpkg\", driver=\"GPKG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bd579e",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fa1e00-90db-47b2-80ce-3f796751c943",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Visualization\n",
    "\n",
    "A simple interactive visualization of the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3c4b40-1473-44fa-b9a9-e525aae5d09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfa2880-cadb-4130-ae68-ab0f8376c62d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cont = widgets.Dropdown(\n",
    "    options=col_list,\n",
    "    value=col_list[0],\n",
    "    description='Column:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "def plot(m):    \n",
    "    grid_notna.plot(column = cont.value, figsize=(20, 10), legend=True)\n",
    "out = widgets.interactive_output(plot, {'m': cont})\n",
    "widgets.VBox([widgets.HBox([cont]), out])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be4ca2f-30aa-483f-9b2b-ddd306aa61fc",
   "metadata": {},
   "source": [
    "### Scatter plot\n",
    " \n",
    "Interactive plot of the considered variables inside the grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665fddbd-3082-472b-ae7e-77fb8848925d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scatter(feature1, feature2):\n",
    "    with plt.style.context(\"ggplot\"):\n",
    "        fig = plt.figure(figsize=(8,4))\n",
    "        plt.scatter(x = grid[feature1], y = grid[feature2], s=20)\n",
    "        \n",
    "        plt.xlabel(feature1)\n",
    "        plt.ylabel(feature2)\n",
    "        plt.title(\"%s vs %s\"%(feature1, feature2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34720a0c-b7e0-4577-8912-52ae391a69c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature1 = widgets.Dropdown(\n",
    "    options=col_list,\n",
    "    value=col_list[0],\n",
    "    description='X:',\n",
    "    disabled=False,\n",
    ")\n",
    "feature2 = widgets.Dropdown(\n",
    "    options=col_list,\n",
    "    value=col_list[0],\n",
    "    description='Y:',\n",
    "    disabled=False,\n",
    ")\n",
    "out = widgets.interactive_output(create_scatter, {'feature1': feature1, 'feature2':feature2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61e22d1-b31e-4bb5-ad81-5fcfb24325a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.VBox([widgets.HBox([feature1, feature2]), out])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a069dd4-af3f-401a-b23a-126fa8bf2421",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
